import argparse
import json
import requests

def getParams():
    '''Parse parameters from the command line'''
    parser = argparse.ArgumentParser(description = """
============
Retrieve ENCODE metadata of ENCFF BAM files from a search url generated by using the ENCODE portal.
Example URLs:
    - All BAM files with the hg19 assembly
https://www.encodeproject.org/search/?type=File&file_format=bam&assembly=hg19&frame=object&format=json&limit=all
    - All BAM files with the hg19 assembly from K562
https://www.encodeproject.org/search/?type=File&file_format=bam&assembly=hg19&frame=object&biosample_ontology.term_name=K562&format=json&limit=all

Use the left bar search filters to narrow down by assay, biosample, etc.

Remember to check for genome assembly!
Remember to set file format to bam!
Remember to use quotation marks around url!
Note: Only "unfiltered alignments" from paired end data will contain FASTQ information. Paired end "alignments" files will not  include FQ1 & FQ2 accesesions.s
============
""", formatter_class = argparse.RawTextHelpFormatter)

    parser.add_argument('-i','--input', metavar='search_url', required=True, help='the search url string. Be sure to check for assembly filter.')
    parser.add_argument('-o','--output', metavar='tsv_fn', required=True, help='the output tab-delimited accessions and relevant metadata')

    args = parser.parse_args()
    return(args)


# Helper: ENCFF to URL to payload
def fetch_data(url):
    # Force return from the server in JSON format
    headers = {'accept': 'application/json'}

    # GET the search result
    response = requests.get(url, headers=headers)

    # Extract the JSON response as a python dictionary
    search_results = response.json()
    return(search_results)


# Main program which takes in input parameters
if __name__ == '__main__':

    # Get params
    args = getParams()

    # Get payload for search
    payload = fetch_data(args.input)
    payload = payload.get("@graph", None)
    if (payload == None):
        print("Error: Returned JSON without \"@graph\"")
        quit()
    # print(json.dumps(data,indent=4))
    # quit()

    # Initialize line_storage
    lines = []

    # Parse payload for each accession
    for data in payload:

        # Save BAM accession
        accession = data.get('accession', 'ENCFFXXXXXX').strip()

        schema_version = data.get('schema_version',"No Schema Version")
        print("====== %s ======" % accession)
        print("v%s" % schema_version)

        # Get File Info
        md5sum = data.get('md5sum', None)
        assembly = data.get('assembly', None)
        # file_size = data.get('file_size', None)
        mapped_run_type = data.get('mapped_run_type', None)  # single-ended, paired-ended
        mapped_read_length = data.get('mapped_read_length', None)  # 36, 101
        output_category = data.get('output_category', None)  # alignments
        output_type = data.get('output_type', None)  # alignments, unfiltered alignments
        # Get Experiment Accession
        ENCSR = data.get('dataset',None)
        # Get Biosample name
        strain = data.get('biosample_ontology',None)
        # Get Assay
        assay_title = data.get('assay_title', None)
        # Get Target
        target = data.get('target',None)

        # Get Library accession
        # ENCLB = data.get('replicate',{'library':{'accession':None}})['library']['accession']
        # print(ENCLB)

        # Future work: add audit information

        # Get info derived from FASTQ
        FQ1 = FQ2 = platform = None
        for dfile in data.get("derived_from",[]):
            durl = "https://www.encodeproject.org" + dfile + "?format=json"
            ddata = fetch_data(durl)
            file_format = ddata.get('file_format', None)
            if (file_format == 'fastq'):
                if (mapped_run_type == 'single-ended'):
                    FQ1 = ddata.get('accession', None)
                    platform = ddata.get('platform', None).get('title', None)
                    break
                paired_end = ddata.get('paired_end')
                if (paired_end == '1'):
                    FQ1 = ddata.get('accession', None)
                    platform = ddata.get('platform', None).get('title', None)
                if (paired_end == '2'):
                    FQ2 = ddata.get('accession', None)


        # Update lines with new metadata
        row = [accession, md5sum, assembly, mapped_run_type, FQ1, FQ2, mapped_read_length, output_category, output_type, platform, ENCSR, strain, assay_title, target]

        lines.append('\t'.join([str(i) for i in row]))

    headers = ["accession", "md5sum", "assembly", "mapped_run_type", "FQ1","FQ2", "mapped_read_length", "output_category", "output_type", "platform", "ENCSR", "strain", "assay_title", "target"]
    # Writing to sample.json
    with open(args.output, "w") as outfile:
        outfile.write('\t'.join(headers) + "\n")
        outfile.write('\n'.join(lines))
