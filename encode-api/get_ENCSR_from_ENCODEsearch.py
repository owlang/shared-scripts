import argparse
import json
import requests

# Info we want:
# Histone and TF (No IgG) in K562
# BAM (hgXX) download URL
# Metadata...ENCSR, ENCFF, Rep#


# Filter weird conditions...
# Get only replicate 1 (or deeper seq?)
# CRISPR okay...
# Skip audit orange?

def getParams():
    '''Parse parameters from the command line'''
    parser = argparse.ArgumentParser(description = """
============
Retrieve ENCODE metadata of ENCSR experiments from a search url generated by using the ENCODE portal.
Example URLs:
    - All ENCSR experiments for "TF ChIP-seq" of non-perturbed K562 samples
https://www.encodeproject.org/search/?type=Experiment&control_type%21=%2A&status=released&assay_title=TF+ChIP-seq&assay_title=Histone+ChIP-seq&biosample_ontology.term_name=K562&assembly=GRCh38&perturbed=false&format=json&limit=all
    - All ENCSR experiments for "polyA plus RNA-seq" from HepG2 samples
https://www.encodeproject.org/search/?type=Experiment&assay_title=polyA+plus+RNA-seq&biosample_ontology.classification=cell+line&biosample_ontology.term_name=HepG2&format=json&limit=all

Use the left bar search filters to narrow down by assay, biosample, etc.

Remember to use quotation marks around url!
============
""", formatter_class = argparse.RawTextHelpFormatter)

    parser.add_argument('-i','--input', metavar='search_url', required=True, help='the search url string. Be sure to check for "Experiment" type.')
    parser.add_argument('-o','--output', metavar='tsv_fn', required=True, help='the output tab-delimited accessions and relevant metadata')

    args = parser.parse_args()
    return(args)


# Helper: ENCFF to URL to payload
def fetch_data(url):
    # Force return from the server in JSON format
    headers = {'accept': 'application/json'}

    # GET the search result
    response = requests.get(url, headers=headers)

    # Extract the JSON response as a python dictionary
    search_results = response.json()
    return(search_results)


# Main program which takes in input parameters
if __name__ == '__main__':

    # Get params
    args = getParams()


    # All ENCFF accessions filtered such that
    # - assay = "TF ChIP-seq" or "Histone ChIP-seq"
    # - biosample = "K562"
    # - genome build = "GRCh38"
    # - did not filter for "not perturbed"
    all_ChIP_BAM_URL="https://www.encodeproject.org/search/?type=File&file_format=bam&assay_title=TF+ChIP-seq&assay_title=Histone+ChIP-seq&biosample_ontology.term_name=K562&assembly=GRCh38&format=json&limit=all"

    # Get payload for accession
    data = fetch_data(all_ChIP_BAM_URL)['@graph']

    # Initialize storage variable
    target2info = {}

    # Extract data from each hit
    # for json in data:

        # Save Target, download_url, ENCSR, ENCFF, replicate number, run_type, sequencing depth to target info

        # Check for existing target entry
        # Is mine "better"?

        # Update if so...


    # Get payload for search
    payload = fetch_data(args.input)
    payload = payload.get("@graph", None)
    if (payload == None):
        print("Error: Returned JSON without \"@graph\"")
        quit()
    # print(json.dumps(data,indent=4))
    # quit()

    # Initialize line_storage
    lines = []

    # Parse payload for each accession
    for data in payload:

        # Save Experiment accession
        accession = data.get('accession', 'ENCSRXXXXXX').strip()
        description = data.get('description', None)

        schema_version = data.get('schema_version',"No Schema Version")
        print("====== %s ======" % accession)
        print("v%s" % schema_version)

        # Get Biosample info
        strain = data.get('biosample_ontology', {}).get('term_name', None)
        biosample_summary = data.get('biosample_summary', None)
        # Get Assay info
        assay_title = data.get('assay_title', None)
        # Get Target
        target_name = data.get('target', None).get('label', None)
        target = data.get('target', {}).get('@id', None)

        # Future work: add audit information

        # Update lines with new metadata
        row = [accession, assay_title, target_name, target, description, strain, biosample_summary]

        lines.append('\t'.join([str(i) for i in row]))

    headers = ["accession", "assay_title", "target_name", "target", "description", "strain", "biosample_summary"]
    # Writing to sample.json
    with open(args.output, "w") as outfile:
        outfile.write('\t'.join(headers) + "\n")
        outfile.write('\n'.join(lines))

    # Write metadata with download URL
    # [ sys.stdout.write('\t'.join(info) + "\n") for info in target2info.values() ]
